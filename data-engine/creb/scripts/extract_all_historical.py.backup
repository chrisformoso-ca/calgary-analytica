#!/usr/bin/env python3
"""
Extract ALL historical CREB data from ALL available PDFs.
This script processes every PDF and combines all unique data points.
"""

import pandas as pd
import pdfplumber
from pathlib import Path
import logging
import re
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HistoricalCREBExtractor:
    def __init__(self, pdf_directory: str):
        self.pdf_directory = Path(pdf_directory)
        self.property_types = {
            'Total': 11,
            'Detached': 13,
            'Semi_Detached': 15,
            'Apartment': 17,
            'Row': 19
        }
        
    def extract_from_all_pdfs(self):
        """Extract data from ALL PDFs and combine unique records."""
        all_city_data = []
        all_district_data = []
        
        # Get all PDFs
        pdfs = sorted(self.pdf_directory.glob("*_Calgary_Monthly_Stats_Package.pdf"))
        logger.info(f"Found {len(pdfs)} PDFs to process")
        
        for pdf_path in pdfs:
            logger.info(f"\nProcessing {pdf_path.name}...")
            
            # Extract city data
            city_data = self.extract_city_data(pdf_path)
            if city_data:
                all_city_data.extend(city_data)
                logger.info(f"  Extracted {len(city_data)} city records")
            
            # Extract district data
            district_data = self.extract_district_data(pdf_path)
            if district_data:
                all_district_data.extend(district_data)
                logger.info(f"  Extracted {len(district_data)} district records")
        
        # Convert to DataFrames and remove duplicates
        if all_city_data:
            city_df = pd.DataFrame(all_city_data)
            city_df = city_df.drop_duplicates(subset=['Date', 'Property_Type'], keep='last')
            city_df = city_df.sort_values(['Date', 'Property_Type'])
            logger.info(f"\nTotal unique city records: {len(city_df)}")
            logger.info(f"Date range: {city_df['Date'].min()} to {city_df['Date'].max()}")
            
            # Save city data
            output_path = Path("/home/chris/calgary-analytica/data-engine/validation/pending/creb_city_all_historical.csv")
            city_df.to_csv(output_path, index=False)
            logger.info(f"Saved to {output_path}")
        
        if all_district_data:
            district_df = pd.DataFrame(all_district_data)
            district_df = district_df.drop_duplicates(
                subset=['date', 'property_type', 'district'], keep='last'
            )
            district_df = district_df.sort_values(['date', 'property_type', 'district'])
            logger.info(f"\nTotal unique district records: {len(district_df)}")
            logger.info(f"Date range: {district_df['date'].min()} to {district_df['date'].max()}")
            
            # Save district data
            output_path = Path("/home/chris/calgary-analytica/data-engine/validation/pending/creb_district_all_historical.csv")
            district_df.to_csv(output_path, index=False)
            logger.info(f"Saved to {output_path}")
    
    def extract_city_data(self, pdf_path):
        """Extract city-wide data from a single PDF."""
        records = []
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for property_type, page_num in self.property_types.items():
                    if len(pdf.pages) >= page_num:
                        page = pdf.pages[page_num - 1]
                        text = page.extract_text()
                        
                        if text:
                            # Parse the page for this property type
                            property_records = self.parse_city_page(text, property_type)
                            records.extend(property_records)
        except Exception as e:
            logger.error(f"Error processing {pdf_path.name}: {e}")
        
        return records
    
    def parse_city_page(self, text, property_type):
        """Parse a city data page."""
        records = []
        lines = text.split('\n')
        
        current_year = None
        
        for line in lines:
            # Look for year headers
            year_match = re.match(r'^(20\d{2})\s+', line)
            if year_match:
                current_year = int(year_match.group(1))
                continue
            
            # Look for data rows (Sales row)
            if current_year and 'Sales' in line:
                # Extract numbers after "Sales"
                numbers = re.findall(r'[\d,]+', line)
                if len(numbers) >= 12:  # Should have 12 months of data
                    for month_idx, sales_str in enumerate(numbers[:12]):
                        month = month_idx + 1
                        date_str = f"{current_year}-{month:02d}"
                        
                        try:
                            sales = int(sales_str.replace(',', ''))
                            
                            # Create basic record (we'll get other metrics from other rows)
                            record = {
                                'Date': date_str,
                                'Property_Type': property_type,
                                'Sales': sales
                            }
                            records.append(record)
                        except:
                            pass
            
            # Look for benchmark price row
            if current_year and ('Benchmark Price' in line or 'Benchmark HPI' in line):
                numbers = re.findall(r'[\d,]+', line)
                if len(numbers) >= 12:
                    for month_idx, price_str in enumerate(numbers[:12]):
                        month = month_idx + 1
                        date_str = f"{current_year}-{month:02d}"
                        
                        try:
                            price = int(price_str.replace(',', ''))
                            
                            # Update existing record if found
                            for record in records:
                                if record['Date'] == date_str and record['Property_Type'] == property_type:
                                    record['Benchmark_Price'] = price
                        except:
                            pass
        
        # Only keep complete records
        complete_records = [r for r in records if 'Benchmark_Price' in r]
        return complete_records
    
    def extract_district_data(self, pdf_path):
        """Extract district data from page 7."""
        records = []
        
        # Parse PDF filename for month/year
        match = re.match(r"(\d{2})_(\d{4})_Calgary", pdf_path.name)
        if not match:
            return records
        
        month, year = int(match.group(1)), int(match.group(2))
        date_str = f"{year}-{month:02d}-01"
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                if len(pdf.pages) >= 7:
                    page = pdf.pages[6]  # Page 7 (0-indexed)
                    text = page.extract_text()
                    
                    if text:
                        records = self.parse_district_page(text, month, year, date_str)
        except Exception as e:
            logger.error(f"Error extracting district data from {pdf_path.name}: {e}")
        
        return records
    
    def parse_district_page(self, text, month, year, date_str):
        """Parse district data from page 7."""
        records = []
        lines = text.split('\n')
        
        # Districts we're looking for
        districts = ['City Centre', 'North East', 'North', 'North West', 
                    'East', 'West', 'South East', 'South']
        
        # Property types on district page
        property_types = ['Detached', 'Semi-Detached', 'Row', 'Apartment']
        
        current_property_type = None
        
        for line in lines:
            # Check for property type headers
            for prop_type in property_types:
                if prop_type in line and not any(d in line for d in districts):
                    current_property_type = prop_type
                    break
            
            # Check for district data
            if current_property_type:
                for district in districts:
                    if district in line:
                        # Extract numbers from the line
                        numbers = re.findall(r'[\d,]+', line.replace(district, ''))
                        
                        if len(numbers) >= 6:  # Need at least 6 numbers
                            try:
                                record = {
                                    'property_type': current_property_type,
                                    'district': district,
                                    'new_sales': int(numbers[0].replace(',', '')),
                                    'new_listings': int(numbers[1].replace(',', '')),
                                    'inventory': int(numbers[2].replace(',', '')),
                                    'benchmark_price': int(numbers[4].replace(',', '')),
                                    'month': month,
                                    'year': year,
                                    'date': date_str
                                }
                                records.append(record)
                            except:
                                pass
        
        return records


if __name__ == "__main__":
    extractor = HistoricalCREBExtractor("/home/chris/calgary-analytica/data-engine/creb/raw")
    extractor.extract_from_all_pdfs()